# ğŸš€ LLM Chat Backend (FastAPI + MongoDB)

This is a **backend component** that facilitates interaction with **LLMs (OpenAI GPT-4o-mini)**. It provides:
- **CRUD operations** for conversations containing queries and responses.
- **LLM query handling** with conversation history as context.
- **Anonymized query storage** in MongoDB for auditing.
- **REST API with OpenAPI docs** for easy integration.

---

## **ğŸ“Œ Features**
âœ… **FastAPI-based backend**  
âœ… **MongoDB for conversation storage**  
âœ… **Dockerized environment**  
âœ… **CRUD endpoints for managing conversations**  
âœ… **Send prompt queries & receive LLM responses**  
âœ… **Automatic logging & anonymization of chat history**  
âœ… **OpenAPI documentation for API usage**  

---

## **ğŸ›  Tech Stack**
| Component  | Technology |
|------------|-----------|
| **Backend** | FastAPI (Python 3.10+) |
| **Database** | MongoDB (via Docker) |
| **ORM** | Beanie (MongoDB ODM) |
| **LLM API** | OpenAI Python Client |
| **Validation** | Pydantic |
| **Containerization** | Docker, Docker Compose |

---

## **ğŸš€ Setup and Running the Application**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo-name.git
cd your-repo-name
```
### **2ï¸âƒ£ Configure Environment Variables**
Duplicate the `.env.example` file and name it `.env`.
It should look like the following:
```bash
MONGO_URI="mongodb://mongo:27017/launchpad_db"
OPENAI_API_KEY="INPUT YOUR OPENAI API KEY HERE"
```
Enter your OpenAI API Secret key as a string
âœ… Notes:
- mongo is the service name inside Docker Compose.
- Do not use localhost inside Docker Compose (use mongo instead).

### **3ï¸âƒ£ Run with Docker Compose**
To build and start both FastAPI & MongoDB, run:
```bash
docker-compose up -d --build
```
âœ… Notes:
- d â†’ Runs in detached mode (in the background).
- -build â†’ Ensures FastAPI is rebuilt.

Check running containers:
```bash
docker ps
```

### **4ï¸âƒ£ Verify MongoDB is Running**
To check if MongoDB is working inside the Docker container, enter:
```bash
docker exec -it mongodb mongosh
```
Then, inside MongoDB shell:
```js
show dbs  # List databases
use launchpad_db  # Switch to project database
show collections  # Show collections
```

### **5ï¸âƒ£ Access the FastAPI Application**
If the two containers are running correctly, you should be able to access:

API Documentation (Swagger UI): http://localhost:8000/docs

You can test the endpoints here. Enter the request body and view the response body. 

## **ğŸ“Œ API Endpoints**
The endpoints were created based off the openai.yaml file provided by the team.

### **1ï¸âƒ£ Create a Conversation**
```http
POST /conversations/
```
Example Request Body:
```json
{
  "name": "My Conversation",
  "params": {
    "temperature": 0.7
  }
}
```
Example Response:
```json
{
  "id": "656a21fb3b3f76f3a2e6b1c3",
  "name": "My Conversation",
  "params": {"temperature": 0.7}
}
```

### **2ï¸âƒ£ Get All Conversations**
```http
GET /conversations/
```
Example Response:
```json
[
  {
    "id": "656a21fb3b3f76f3a2e6b1c3",
    "name": "My Conversation",
    "params": {
      "temperature": 0.7
    }
  },
  {
    "id": "656a21fb3b3f76f3a2e6b1c4",
    "name": "Another Conversation",
    "params": {
      "temperature": 0.5
    }
  }
]
```
### **3ï¸âƒ£ Get a Specific Conversation**
```http
GET /conversations/{conversation_id}
```
Example Response:
```json
{
  "id": "656a21fb3b3f76f3a2e6b1c3",
  "name": "My Conversation",
  "params": {
    "temperature": 0.7
  },
  "tokens": 100,
  "pinned": false,
  "prompts": [
    {"role": "user", "content": "Hello!"},
    {"role": "assistant", "content": "Hi, how can I assist you?"}
  ],
  "modifications": {}
}
```
Error Response:
```json
{
  "detail": {
    "code": 404,
    "message": "Specified resource(s) was not found"
  }
}
```
### **4ï¸âƒ£ Update a Conversation**
```http
PUT /conversations/{conversation_id}
```
Example Request Body:
```json
{
  "name": "Updated Conversation",
  "params": {
    "temperature": 0.9,
    "max_tokens": 200
  }
}
```
Example Response:
```json
{
  "id": "656a21fb3b3f76f3a2e6b1c3",
  "name": "Updated Conversation",
  "params": {
    "temperature": 0.9,
    "max_tokens": 200
  }
}
```
### **5ï¸âƒ£ Delete a Conversation**
```http
DELETE /conversations/{conversation_id}
```

### **6ï¸âƒ£ Send a Prompt to LLM**
```http
POST /conversations/{conversation_id}
```
Example Request Body:
```json
{
  "content": "Hello, how are you?"
}
```
Example Response:
```json
{
  "message": "I'm doing well, thank you!"
}
```
## **ğŸ“Œ Stopping & Managing Containers**
Stop the running contaainers
```bash
docker-compose down
```
Restart the application
```bash
docker-compose up -d
```

## **ğŸ“Œ Project Structure**

```plaintext
/your-repo
â”‚â”€â”€ /app                 # FastAPI source code
â”‚   â”œâ”€â”€ main.py          # FastAPI entry point
â”‚   â”œâ”€â”€ models/          # Pydantic models
â”‚   â”œâ”€â”€ routes/          # FastAPI endpoints
â”‚   â”œâ”€â”€ config/          # MongoDB connection
â”‚â”€â”€ Dockerfile           # FastAPI Docker setup
â”‚â”€â”€ docker-compose.yml   # Docker Compose for MongoDB + FastAPI
â”‚â”€â”€ requirements.txt     # Python dependencies
â”‚â”€â”€ .env                 # Environment variables
|â”€â”€ .env.example         # Example of .env file
|â”€â”€ .gitignore           # Contains untracked file names
â”‚â”€â”€ README.md            # This file
```
## **ğŸ“Œ Troubleshooting**
```bash
Error: Port 27017 is already allocated
```
Open docker terminal and enter this command to see the running containers:
```bash
docker ps
```
Check the name of the container that is running on Port 27017. 
```bash
docker stop <name of container>
```
Then restart by running
```bash
docker-compose up -d
```